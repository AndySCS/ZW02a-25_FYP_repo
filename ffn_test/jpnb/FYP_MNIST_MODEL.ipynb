{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qWynEGbb7FIO"
      ],
      "authorship_tag": "ABX9TyOb8uq2vq5Pm4sFKW5mX3Ar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndySCS/ZW02a-25_FYP_repo/blob/main/ffn_test/jpnb/FYP_MNIST_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UupKmABS21G5"
      },
      "outputs": [],
      "source": [
        "#import pkgs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision as TV\n",
        "from IPython.display import clear_output\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#download dataset"
      ],
      "metadata": {
        "id": "cLfJoISo5yLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TV.datasets.MNIST(root=\"data\", train=True, transform=ToTensor(), download=True)\n",
        "test_data = TV.datasets.MNIST(root=\"data\", train=False, transform=ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "rRGjyoR25f0i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "99s7057zFOIq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    img, label = train_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "DofCeDidB8Cj",
        "outputId": "64fd8e86-84ae-44f3-8e69-daf665b3d2e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get device"
      ],
      "metadata": {
        "id": "qWynEGbb7FIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC4uYy4a7GvQ",
        "outputId": "5a85caab-4f7b-4f20-c404-260fa531d098"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#define model class"
      ],
      "metadata": {
        "id": "SEVERkdJ6UqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear_relu_stack = nn.Sequential(\n",
        "          nn.Linear(28*28, 128),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(p=0.5),\n",
        "          nn.Linear(128, 10),\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      logits = self.linear_relu_stack(x)\n",
        "      #logits = nn.functional.log_softmax(logits, dim=1)\n",
        "      return logits"
      ],
      "metadata": {
        "id": "FCLJV6e26mKg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an6CDLVy7MZJ",
        "outputId": "63f2644a-6d4e-4e90-dfb4-d2a1166c66d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train the model"
      ],
      "metadata": {
        "id": "1xf9d1fL6_sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3"
      ],
      "metadata": {
        "id": "WfkiDSW_Cc69"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)  # if using GPU later\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss_val = loss.item()\n",
        "            current = (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (torch.softmax(pred, dim=1).argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "XPr0PI3c75co"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX4ENMsQCXbg",
        "outputId": "fe982629-95fa-4e75-f4dc-821798a57470"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.316027  [   32/60000]\n",
            "loss: 2.316411  [ 3232/60000]\n",
            "loss: 2.280066  [ 6432/60000]\n",
            "loss: 2.258033  [ 9632/60000]\n",
            "loss: 2.196616  [12832/60000]\n",
            "loss: 2.188686  [16032/60000]\n",
            "loss: 2.169679  [19232/60000]\n",
            "loss: 2.170967  [22432/60000]\n",
            "loss: 2.169399  [25632/60000]\n",
            "loss: 2.102888  [28832/60000]\n",
            "loss: 2.149658  [32032/60000]\n",
            "loss: 2.176952  [35232/60000]\n",
            "loss: 2.018304  [38432/60000]\n",
            "loss: 2.068750  [41632/60000]\n",
            "loss: 1.890656  [44832/60000]\n",
            "loss: 2.041049  [48032/60000]\n",
            "loss: 1.996663  [51232/60000]\n",
            "loss: 1.908328  [54432/60000]\n",
            "loss: 1.858690  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.8%, Avg loss: 1.848635 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.858081  [   32/60000]\n",
            "loss: 1.869843  [ 3232/60000]\n",
            "loss: 1.848228  [ 6432/60000]\n",
            "loss: 1.800400  [ 9632/60000]\n",
            "loss: 1.770746  [12832/60000]\n",
            "loss: 1.672353  [16032/60000]\n",
            "loss: 1.627401  [19232/60000]\n",
            "loss: 1.657145  [22432/60000]\n",
            "loss: 1.769796  [25632/60000]\n",
            "loss: 1.561606  [28832/60000]\n",
            "loss: 1.540636  [32032/60000]\n",
            "loss: 1.467097  [35232/60000]\n",
            "loss: 1.466170  [38432/60000]\n",
            "loss: 1.539256  [41632/60000]\n",
            "loss: 1.345578  [44832/60000]\n",
            "loss: 1.617831  [48032/60000]\n",
            "loss: 1.275226  [51232/60000]\n",
            "loss: 1.331451  [54432/60000]\n",
            "loss: 1.326078  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.5%, Avg loss: 1.275870 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.513879  [   32/60000]\n",
            "loss: 1.338097  [ 3232/60000]\n",
            "loss: 1.346200  [ 6432/60000]\n",
            "loss: 1.428976  [ 9632/60000]\n",
            "loss: 1.360973  [12832/60000]\n",
            "loss: 1.201976  [16032/60000]\n",
            "loss: 1.086446  [19232/60000]\n",
            "loss: 1.306077  [22432/60000]\n",
            "loss: 1.058605  [25632/60000]\n",
            "loss: 1.266970  [28832/60000]\n",
            "loss: 1.077282  [32032/60000]\n",
            "loss: 1.073239  [35232/60000]\n",
            "loss: 0.939823  [38432/60000]\n",
            "loss: 0.934195  [41632/60000]\n",
            "loss: 1.217981  [44832/60000]\n",
            "loss: 1.137655  [48032/60000]\n",
            "loss: 0.926933  [51232/60000]\n",
            "loss: 1.192032  [54432/60000]\n",
            "loss: 1.020829  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.0%, Avg loss: 0.918805 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.105646  [   32/60000]\n",
            "loss: 0.927828  [ 3232/60000]\n",
            "loss: 1.177298  [ 6432/60000]\n",
            "loss: 1.097280  [ 9632/60000]\n",
            "loss: 0.883491  [12832/60000]\n",
            "loss: 0.847982  [16032/60000]\n",
            "loss: 0.981132  [19232/60000]\n",
            "loss: 1.039274  [22432/60000]\n",
            "loss: 0.875403  [25632/60000]\n",
            "loss: 1.009035  [28832/60000]\n",
            "loss: 0.814391  [32032/60000]\n",
            "loss: 0.867605  [35232/60000]\n",
            "loss: 1.083027  [38432/60000]\n",
            "loss: 0.944071  [41632/60000]\n",
            "loss: 0.915652  [44832/60000]\n",
            "loss: 0.924403  [48032/60000]\n",
            "loss: 0.767682  [51232/60000]\n",
            "loss: 1.014421  [54432/60000]\n",
            "loss: 1.093614  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.2%, Avg loss: 0.734650 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.968492  [   32/60000]\n",
            "loss: 1.022977  [ 3232/60000]\n",
            "loss: 0.749201  [ 6432/60000]\n",
            "loss: 0.680886  [ 9632/60000]\n",
            "loss: 0.717044  [12832/60000]\n",
            "loss: 0.689173  [16032/60000]\n",
            "loss: 0.688252  [19232/60000]\n",
            "loss: 0.760954  [22432/60000]\n",
            "loss: 0.784327  [25632/60000]\n",
            "loss: 0.855041  [28832/60000]\n",
            "loss: 0.897552  [32032/60000]\n",
            "loss: 1.003806  [35232/60000]\n",
            "loss: 0.887658  [38432/60000]\n",
            "loss: 0.617852  [41632/60000]\n",
            "loss: 0.869067  [44832/60000]\n",
            "loss: 0.810716  [48032/60000]\n",
            "loss: 0.716573  [51232/60000]\n",
            "loss: 0.649705  [54432/60000]\n",
            "loss: 0.619780  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.629841 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.641814  [   32/60000]\n",
            "loss: 0.863038  [ 3232/60000]\n",
            "loss: 0.768015  [ 6432/60000]\n",
            "loss: 0.743264  [ 9632/60000]\n",
            "loss: 0.676098  [12832/60000]\n",
            "loss: 0.646570  [16032/60000]\n",
            "loss: 0.731957  [19232/60000]\n",
            "loss: 0.645808  [22432/60000]\n",
            "loss: 0.643874  [25632/60000]\n",
            "loss: 0.941032  [28832/60000]\n",
            "loss: 0.613709  [32032/60000]\n",
            "loss: 0.526103  [35232/60000]\n",
            "loss: 0.535310  [38432/60000]\n",
            "loss: 0.664125  [41632/60000]\n",
            "loss: 0.568454  [44832/60000]\n",
            "loss: 0.543750  [48032/60000]\n",
            "loss: 0.513984  [51232/60000]\n",
            "loss: 0.689231  [54432/60000]\n",
            "loss: 0.780569  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.563461 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.617468  [   32/60000]\n",
            "loss: 0.720326  [ 3232/60000]\n",
            "loss: 0.856591  [ 6432/60000]\n",
            "loss: 0.564407  [ 9632/60000]\n",
            "loss: 0.654630  [12832/60000]\n",
            "loss: 0.510505  [16032/60000]\n",
            "loss: 0.680781  [19232/60000]\n",
            "loss: 0.662394  [22432/60000]\n",
            "loss: 0.813484  [25632/60000]\n",
            "loss: 0.780615  [28832/60000]\n",
            "loss: 0.709251  [32032/60000]\n",
            "loss: 0.557501  [35232/60000]\n",
            "loss: 0.583487  [38432/60000]\n",
            "loss: 0.683794  [41632/60000]\n",
            "loss: 0.948396  [44832/60000]\n",
            "loss: 0.700626  [48032/60000]\n",
            "loss: 0.671002  [51232/60000]\n",
            "loss: 0.704538  [54432/60000]\n",
            "loss: 0.500944  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.516909 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.684578  [   32/60000]\n",
            "loss: 0.407185  [ 3232/60000]\n",
            "loss: 0.316199  [ 6432/60000]\n",
            "loss: 0.605067  [ 9632/60000]\n",
            "loss: 0.644123  [12832/60000]\n",
            "loss: 0.703049  [16032/60000]\n",
            "loss: 0.719689  [19232/60000]\n",
            "loss: 0.705575  [22432/60000]\n",
            "loss: 0.842028  [25632/60000]\n",
            "loss: 0.504846  [28832/60000]\n",
            "loss: 0.664821  [32032/60000]\n",
            "loss: 0.805250  [35232/60000]\n",
            "loss: 0.745426  [38432/60000]\n",
            "loss: 0.502778  [41632/60000]\n",
            "loss: 0.795574  [44832/60000]\n",
            "loss: 0.493907  [48032/60000]\n",
            "loss: 0.303704  [51232/60000]\n",
            "loss: 0.685306  [54432/60000]\n",
            "loss: 0.624400  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.483201 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.503117  [   32/60000]\n",
            "loss: 0.729192  [ 3232/60000]\n",
            "loss: 0.488990  [ 6432/60000]\n",
            "loss: 0.345139  [ 9632/60000]\n",
            "loss: 0.624961  [12832/60000]\n",
            "loss: 0.388316  [16032/60000]\n",
            "loss: 0.342411  [19232/60000]\n",
            "loss: 0.733599  [22432/60000]\n",
            "loss: 0.529291  [25632/60000]\n",
            "loss: 0.402337  [28832/60000]\n",
            "loss: 0.749835  [32032/60000]\n",
            "loss: 0.607018  [35232/60000]\n",
            "loss: 0.458197  [38432/60000]\n",
            "loss: 0.595514  [41632/60000]\n",
            "loss: 0.771687  [44832/60000]\n",
            "loss: 0.531225  [48032/60000]\n",
            "loss: 0.415813  [51232/60000]\n",
            "loss: 0.595318  [54432/60000]\n",
            "loss: 0.380535  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.455772 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.584913  [   32/60000]\n",
            "loss: 0.442752  [ 3232/60000]\n",
            "loss: 0.515949  [ 6432/60000]\n",
            "loss: 0.610184  [ 9632/60000]\n",
            "loss: 0.602550  [12832/60000]\n",
            "loss: 0.426378  [16032/60000]\n",
            "loss: 0.710054  [19232/60000]\n",
            "loss: 0.457386  [22432/60000]\n",
            "loss: 0.477402  [25632/60000]\n",
            "loss: 0.578261  [28832/60000]\n",
            "loss: 0.752473  [32032/60000]\n",
            "loss: 0.520036  [35232/60000]\n",
            "loss: 0.504321  [38432/60000]\n",
            "loss: 0.609478  [41632/60000]\n",
            "loss: 0.757347  [44832/60000]\n",
            "loss: 0.493026  [48032/60000]\n",
            "loss: 0.703332  [51232/60000]\n",
            "loss: 0.661093  [54432/60000]\n",
            "loss: 0.548466  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.434747 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.860241  [   32/60000]\n",
            "loss: 0.279202  [ 3232/60000]\n",
            "loss: 0.509488  [ 6432/60000]\n",
            "loss: 0.564610  [ 9632/60000]\n",
            "loss: 0.387927  [12832/60000]\n",
            "loss: 0.554450  [16032/60000]\n",
            "loss: 0.816548  [19232/60000]\n",
            "loss: 0.651297  [22432/60000]\n",
            "loss: 0.483972  [25632/60000]\n",
            "loss: 0.621503  [28832/60000]\n",
            "loss: 0.547722  [32032/60000]\n",
            "loss: 0.552954  [35232/60000]\n",
            "loss: 0.479487  [38432/60000]\n",
            "loss: 0.658093  [41632/60000]\n",
            "loss: 0.668642  [44832/60000]\n",
            "loss: 0.322415  [48032/60000]\n",
            "loss: 0.777716  [51232/60000]\n",
            "loss: 0.890046  [54432/60000]\n",
            "loss: 0.577055  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.417368 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.549975  [   32/60000]\n",
            "loss: 0.446929  [ 3232/60000]\n",
            "loss: 0.445376  [ 6432/60000]\n",
            "loss: 0.618639  [ 9632/60000]\n",
            "loss: 0.629326  [12832/60000]\n",
            "loss: 0.569534  [16032/60000]\n",
            "loss: 0.516056  [19232/60000]\n",
            "loss: 0.536443  [22432/60000]\n",
            "loss: 0.432197  [25632/60000]\n",
            "loss: 0.287541  [28832/60000]\n",
            "loss: 0.674403  [32032/60000]\n",
            "loss: 0.452825  [35232/60000]\n",
            "loss: 0.326406  [38432/60000]\n",
            "loss: 0.377359  [41632/60000]\n",
            "loss: 0.498501  [44832/60000]\n",
            "loss: 0.546320  [48032/60000]\n",
            "loss: 0.437692  [51232/60000]\n",
            "loss: 0.508339  [54432/60000]\n",
            "loss: 0.429449  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.402854 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.264014  [   32/60000]\n",
            "loss: 0.939490  [ 3232/60000]\n",
            "loss: 0.398147  [ 6432/60000]\n",
            "loss: 0.403549  [ 9632/60000]\n",
            "loss: 0.481307  [12832/60000]\n",
            "loss: 0.645353  [16032/60000]\n",
            "loss: 0.672549  [19232/60000]\n",
            "loss: 0.379245  [22432/60000]\n",
            "loss: 0.546796  [25632/60000]\n",
            "loss: 0.343398  [28832/60000]\n",
            "loss: 0.544964  [32032/60000]\n",
            "loss: 1.024101  [35232/60000]\n",
            "loss: 0.392333  [38432/60000]\n",
            "loss: 0.732698  [41632/60000]\n",
            "loss: 0.612742  [44832/60000]\n",
            "loss: 0.395539  [48032/60000]\n",
            "loss: 0.408577  [51232/60000]\n",
            "loss: 0.577316  [54432/60000]\n",
            "loss: 0.485716  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.7%, Avg loss: 0.390088 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.672986  [   32/60000]\n",
            "loss: 0.360098  [ 3232/60000]\n",
            "loss: 0.570729  [ 6432/60000]\n",
            "loss: 0.483485  [ 9632/60000]\n",
            "loss: 0.455728  [12832/60000]\n",
            "loss: 0.256472  [16032/60000]\n",
            "loss: 0.554157  [19232/60000]\n",
            "loss: 0.714571  [22432/60000]\n",
            "loss: 0.574846  [25632/60000]\n",
            "loss: 0.322642  [28832/60000]\n",
            "loss: 0.543755  [32032/60000]\n",
            "loss: 0.425177  [35232/60000]\n",
            "loss: 0.287156  [38432/60000]\n",
            "loss: 0.381343  [41632/60000]\n",
            "loss: 0.485100  [44832/60000]\n",
            "loss: 0.550328  [48032/60000]\n",
            "loss: 0.443700  [51232/60000]\n",
            "loss: 0.409568  [54432/60000]\n",
            "loss: 0.447654  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.378875 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.417163  [   32/60000]\n",
            "loss: 0.638635  [ 3232/60000]\n",
            "loss: 0.548987  [ 6432/60000]\n",
            "loss: 0.438228  [ 9632/60000]\n",
            "loss: 0.405376  [12832/60000]\n",
            "loss: 0.729687  [16032/60000]\n",
            "loss: 0.415901  [19232/60000]\n",
            "loss: 0.541391  [22432/60000]\n",
            "loss: 0.469482  [25632/60000]\n",
            "loss: 0.275855  [28832/60000]\n",
            "loss: 0.446912  [32032/60000]\n",
            "loss: 0.473494  [35232/60000]\n",
            "loss: 0.472568  [38432/60000]\n",
            "loss: 0.509442  [41632/60000]\n",
            "loss: 0.596953  [44832/60000]\n",
            "loss: 0.640047  [48032/60000]\n",
            "loss: 0.551837  [51232/60000]\n",
            "loss: 0.467961  [54432/60000]\n",
            "loss: 0.636843  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.1%, Avg loss: 0.369379 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.321301  [   32/60000]\n",
            "loss: 0.587500  [ 3232/60000]\n",
            "loss: 0.768185  [ 6432/60000]\n",
            "loss: 0.546832  [ 9632/60000]\n",
            "loss: 0.524820  [12832/60000]\n",
            "loss: 0.607459  [16032/60000]\n",
            "loss: 0.384717  [19232/60000]\n",
            "loss: 0.353621  [22432/60000]\n",
            "loss: 0.422550  [25632/60000]\n",
            "loss: 0.316506  [28832/60000]\n",
            "loss: 0.366058  [32032/60000]\n",
            "loss: 0.333190  [35232/60000]\n",
            "loss: 0.605689  [38432/60000]\n",
            "loss: 0.476615  [41632/60000]\n",
            "loss: 0.365353  [44832/60000]\n",
            "loss: 0.568336  [48032/60000]\n",
            "loss: 0.288406  [51232/60000]\n",
            "loss: 0.555698  [54432/60000]\n",
            "loss: 0.407915  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.360683 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.538669  [   32/60000]\n",
            "loss: 0.403476  [ 3232/60000]\n",
            "loss: 0.338247  [ 6432/60000]\n",
            "loss: 0.393769  [ 9632/60000]\n",
            "loss: 0.585320  [12832/60000]\n",
            "loss: 0.328612  [16032/60000]\n",
            "loss: 0.337830  [19232/60000]\n",
            "loss: 0.493828  [22432/60000]\n",
            "loss: 0.536546  [25632/60000]\n",
            "loss: 0.638876  [28832/60000]\n",
            "loss: 0.659892  [32032/60000]\n",
            "loss: 0.459501  [35232/60000]\n",
            "loss: 0.544006  [38432/60000]\n",
            "loss: 0.863603  [41632/60000]\n",
            "loss: 0.648046  [44832/60000]\n",
            "loss: 0.460027  [48032/60000]\n",
            "loss: 0.576272  [51232/60000]\n",
            "loss: 0.553487  [54432/60000]\n",
            "loss: 0.389082  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.352878 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.262346  [   32/60000]\n",
            "loss: 0.326104  [ 3232/60000]\n",
            "loss: 0.488698  [ 6432/60000]\n",
            "loss: 0.400498  [ 9632/60000]\n",
            "loss: 0.362678  [12832/60000]\n",
            "loss: 0.447331  [16032/60000]\n",
            "loss: 0.412131  [19232/60000]\n",
            "loss: 0.658256  [22432/60000]\n",
            "loss: 0.535822  [25632/60000]\n",
            "loss: 0.642241  [28832/60000]\n",
            "loss: 0.290067  [32032/60000]\n",
            "loss: 0.504578  [35232/60000]\n",
            "loss: 0.369227  [38432/60000]\n",
            "loss: 0.185934  [41632/60000]\n",
            "loss: 0.396646  [44832/60000]\n",
            "loss: 0.598896  [48032/60000]\n",
            "loss: 0.302055  [51232/60000]\n",
            "loss: 0.459429  [54432/60000]\n",
            "loss: 0.435146  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 0.345547 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.555137  [   32/60000]\n",
            "loss: 0.561591  [ 3232/60000]\n",
            "loss: 0.378182  [ 6432/60000]\n",
            "loss: 0.780179  [ 9632/60000]\n",
            "loss: 0.404546  [12832/60000]\n",
            "loss: 0.350123  [16032/60000]\n",
            "loss: 0.366828  [19232/60000]\n",
            "loss: 0.313484  [22432/60000]\n",
            "loss: 0.793352  [25632/60000]\n",
            "loss: 0.429197  [28832/60000]\n",
            "loss: 0.440561  [32032/60000]\n",
            "loss: 0.540611  [35232/60000]\n",
            "loss: 0.378366  [38432/60000]\n",
            "loss: 0.180823  [41632/60000]\n",
            "loss: 0.218489  [44832/60000]\n",
            "loss: 0.403343  [48032/60000]\n",
            "loss: 0.449332  [51232/60000]\n",
            "loss: 0.246280  [54432/60000]\n",
            "loss: 0.410088  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.339777 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.297256  [   32/60000]\n",
            "loss: 0.456139  [ 3232/60000]\n",
            "loss: 0.332645  [ 6432/60000]\n",
            "loss: 0.249915  [ 9632/60000]\n",
            "loss: 0.373605  [12832/60000]\n",
            "loss: 0.836823  [16032/60000]\n",
            "loss: 0.459656  [19232/60000]\n",
            "loss: 0.335751  [22432/60000]\n",
            "loss: 0.366221  [25632/60000]\n",
            "loss: 0.207458  [28832/60000]\n",
            "loss: 0.375893  [32032/60000]\n",
            "loss: 0.183800  [35232/60000]\n",
            "loss: 0.528178  [38432/60000]\n",
            "loss: 0.468469  [41632/60000]\n",
            "loss: 0.429832  [44832/60000]\n",
            "loss: 0.407833  [48032/60000]\n",
            "loss: 0.437068  [51232/60000]\n",
            "loss: 0.440441  [54432/60000]\n",
            "loss: 0.341022  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.333524 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#save model"
      ],
      "metadata": {
        "id": "-QzqJY7dH-p_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "d466UGeTIAif"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XtKIzHTIIeEw",
        "outputId": "00eed55a-575e-4c27-a956-d856415b9f77"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b2cc2350-ad42-4477-8598-64c6645cd6d5\", \"model.pth\", 409481)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#quant model"
      ],
      "metadata": {
        "id": "bQDi5gUgIlTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.ao.quantization as quant\n",
        "\n",
        "# 2. Specify quantization configuration\n",
        "model.qconfig = quant.get_default_qconfig(\"fbgemm\")  # backend for x86 CPUs\n",
        "# 3. Prepare model for calibration\n",
        "prepared_model = quant.prepare_fx(model, {\"\": model.qconfig})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "a9f5Sqxw_UjY",
        "outputId": "c18bd7fb-2ff2-44df-ac28-2a2a6b127a9c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torch.ao.quantization' has no attribute 'prepare_fx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4231134028.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_qconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fbgemm\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# backend for x86 CPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 3. Prepare model for calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprepared_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.ao.quantization' has no attribute 'prepare_fx'"
          ]
        }
      ]
    }
  ]
}